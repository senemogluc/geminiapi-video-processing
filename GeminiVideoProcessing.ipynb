{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e85c151",
   "metadata": {},
   "source": [
    "# Gemini Video Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f4989",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "049562b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09faa13",
   "metadata": {},
   "source": [
    "## Gemini Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1def5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Gemini\n",
    "class GeminiVideoProcessor:\n",
    "    \"\"\"Gemini Video Processor\"\"\"\n",
    "\n",
    "    def __init__(self, model_name=\"gemini-2.5-flash\"):\n",
    "        \"\"\"\n",
    "        Initialize Gemini with a pre-trained model\n",
    "\n",
    "        Args:\n",
    "            model_name: HuggingFace model name for Gemini\n",
    "        \"\"\"\n",
    "        #from google.colab import userdata\n",
    "        #api_key = userdata.get('GEMINI_API_KEY')\n",
    "\n",
    "        api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        print(f\"Loading Gemini model: {model_name}\")\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        print(\"✅ Gemini loaded successfully!\")\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def _wait_file_active(self, file_name: str, timeout: int = 600, interval: float = 2.0):\n",
    "        \"\"\"Poll the uploaded file until it becomes ACTIVE.\"\"\"\n",
    "        start = time.time()\n",
    "        last_state = None\n",
    "        while True:\n",
    "            f = self.client.files.get(name=file_name)\n",
    "            last_state = getattr(f, \"state\", None)\n",
    "            if last_state == \"ACTIVE\":\n",
    "                return f\n",
    "            if last_state in (\"FAILED\", \"DELETED\"):\n",
    "                raise RuntimeError(f\"File {file_name} ended in state {last_state}.\")\n",
    "            if time.time() - start > timeout:\n",
    "                raise TimeoutError(f\"Timed out waiting for file {file_name} to become ACTIVE (last state={last_state}).\")\n",
    "            time.sleep(interval)\n",
    "    \n",
    "    def upload_video(self, video_path: str, prompt: str) -> str:\n",
    "        myfile = self.client.files.upload(\n",
    "            file=video_path,\n",
    "            config=types.UploadFileConfig(\n",
    "                display_name=os.path.basename(video_path),\n",
    "                mime_type=\"video/mp4\",\n",
    "            )\n",
    "        )\n",
    "        myfile = self._wait_file_active(myfile.name)\n",
    "\n",
    "        response = self.client.models.generate_content(model=self.model_name, contents=[myfile, prompt])\n",
    "\n",
    "        return response.text\n",
    "    \n",
    "    def pass_video_data(self, video_path: str, prompt: str) -> str:\n",
    "        # Only for videos of size <20Mb\n",
    "        video_bytes = open(video_path, 'rb').read()\n",
    "\n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model_name,\n",
    "            contents=types.Content(\n",
    "                parts=[\n",
    "                    types.Part(\n",
    "                        inline_data=types.Blob(data=video_bytes, mime_type='video/mp4')\n",
    "                    ),\n",
    "                    types.Part(text=prompt)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return response.text\n",
    "    \n",
    "    def pass_youtube_link(self, youtube_url: str, prompt: str) -> str:\n",
    "        response = self.client.models.generate_content(\n",
    "            model=self.model_name,\n",
    "            contents=types.Content(\n",
    "                parts=[\n",
    "                    types.Part(\n",
    "                        file_data=types.FileData(file_uri=youtube_url)\n",
    "                    ),\n",
    "                    types.Part(text=prompt)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0b460",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "03c6ab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Gemini model: gemini-2.5-flash\n",
      "✅ Gemini loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "gemini = GeminiVideoProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274ba8b7",
   "metadata": {},
   "source": [
    "### Video Process with YouTube Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "347f7b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During a press conference, Donald Trump strongly criticized U.S. intelligence agencies for allowing \"false and fake\" information to be released to the public, comparing it to actions by Nazi Germany. He attacked media outlets like Buzzfeed and CNN for publishing these reports, citing a false claim about his lawyer, Michael Cohen, being in Prague as an example of fabricated information. He then emphatically refused to answer a question from a CNN reporter, pointing and repeating, \"You are fake news.\"'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini.pass_youtube_link(\"https://www.youtube.com/watch?v=W6ZHY0E4_Wg\", \"Summarize video in 3 sentences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4a0a4f",
   "metadata": {},
   "source": [
    "### Video Process with Local File >20 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9b6649cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video features Stephen Curry, LeBron James, and JJ Redick sitting at a table, drinking wine, and discussing basketball.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini.upload_video(\"files/videos/lebron.mp4\", \"Summarize video in a sentence.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa789e9",
   "metadata": {},
   "source": [
    "### Video Process with Local File <20 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8336f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The video features LeBron James discussing basketball players, then cuts to Stephen Curry and others entering a room, and concludes with LeBron, Stephen Curry, and another man toasting wine glasses.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini.pass_video_data(\"files/videos/lebron.mp4\", \"Summarize video in a sentence.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
